{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2961e1f0-678f-413e-9722-eff1f2ac167b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelgalarnyk/opt/anaconda3/envs/aclready_env/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/michaelgalarnyk/opt/anaconda3/envs/aclready_env/lib/python3.11/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Imports from langchain (Priyanshu)\n",
    "#from langchain_community.document_loaders import DirectoryLoader\n",
    "#from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Lang\n",
    "from langchain.schema import Document\n",
    "from langchain_together.embeddings import TogetherEmbeddings\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf7d902-dd75-4712-b0cd-c5d307ce6765",
   "metadata": {},
   "source": [
    "## Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f862ab-38f1-4e1e-a614-b4f60992fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "togetherai_api_key = os.getenv('TOGETHERAI_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb3aa9c-9451-472f-a4b5-376b0f35a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#togetherai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78baf3ed-0aae-4dcd-8d1c-a46a67422e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b24962-687e-4dd9-b006-5b7ad65fad78",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f301f3-e001-4ab1-b6b0-fc3f2e067fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_file = '../resources/tex_examples/FOMCacl2023.tex'\n",
    "\n",
    "def read_latex_doc(tex_file):\n",
    "    \"\"\"\n",
    "    input: insert .tex document path\n",
    "    \n",
    "    return: chunks\n",
    "    \"\"\"\n",
    "\n",
    "    with open(tex_file, 'r') as file:\n",
    "        tex_content = file.read()\n",
    "    \n",
    "    # Define patterns for sections, subsections, paragraphs, and labels\n",
    "    #pattern = re.compile(r'\\\\(begin|section|subsection|paragraph)\\*?{[^}]*}')\n",
    "    \n",
    "    # Split using lookahead to include the split point in the result\n",
    "    #chunks = re.split(r'(?=\\\\(begin|section|subsection|paragraph)\\*?{[^}]*})', tex_content)\n",
    "\n",
    "    # Define patterns for sections, subsections, paragraphs, and labels\n",
    "    pattern = re.compile(r'\\\\(section)\\*?{[^}]*}')\n",
    "    \n",
    "    # Split using lookahead to include the split point in the result\n",
    "    chunks = re.split(r'(?=\\\\(section)\\*?{[^}]*})', tex_content)\n",
    "    \n",
    "    combined_chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for i in range(0, len(chunks), 2):\n",
    "        if i + 1 < len(chunks):\n",
    "            if pattern.match(chunks[i]):\n",
    "                if current_chunk:\n",
    "                    combined_chunks.append(current_chunk)\n",
    "                current_chunk = chunks[i] + chunks[i + 1]\n",
    "            else:\n",
    "                current_chunk += chunks[i] + chunks[i + 1]\n",
    "        else:\n",
    "            current_chunk += chunks[i]\n",
    "    if current_chunk:\n",
    "        combined_chunks.append(current_chunk)\n",
    "    \n",
    "\n",
    "    return(combined_chunks)\n",
    "\n",
    "def parse_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Rutwik parse pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        text = \"\"\n",
    "        links = []\n",
    "\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "                for annot in page.annots:\n",
    "                    if 'uri' in annot:\n",
    "                        links.append(annot['uri'])\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"links\": links\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def convert_latex_chunks(list_chunks):\n",
    "    \"\"\"\n",
    "    input: list of latex chunks\n",
    "\n",
    "    return: list of plain text chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert LaTeX to plain text\n",
    "    latex_converter = LatexNodes2Text()\n",
    "    plain_chunks = [latex_converter.latex_to_text(chunk) for chunk in chunks]\n",
    "    \n",
    "    return plain_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918f4b48-7fcd-4002-b0fc-3b367c9e5145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentence transformer model for retrieval\n",
    "#retriever = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load LLaMA 3 model and tokenizer\n",
    "#llama_model = AutoModelForCausalLM.from_pretrained('path_to_llama_model')\n",
    "#llama_tokenizer = AutoTokenizer.from_pretrained('path_to_llama_tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa7bb1-0d01-4820-92fe-5460fed87006",
   "metadata": {},
   "source": [
    "## Analyze Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3595475a-e079-4fd0-9428-75bf575451d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_chunks = read_latex_doc(tex_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379de7b0-8b03-44c0-a7d8-166da333cb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9e4a90e-4148-46a6-a3da-3a8913b49817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\section{Dataset}\\n\\\\subsection{FOMC Data}\\n\\nThe datasets we build are composed of three different types of data: meeting minutes, press conference transcripts, and speeches from the FOMC.\\nMeeting minutes are defined as reports derived from the eight annually scheduled meetings of the FOMC. Press conference transcripts, meanwhile, are transcripts of the prepared remarks, followed by the Q\\\\&A session between the Federal Reserve chair and press reporters. Lastly, speeches were defined as any talk given by a Federal Reserve official. We limit our datasets to an end release date of October 15th, 2022, and attempt to collect as far back as possible for each category prior to this date.\\n\\nThe meeting minutes and speeches spanned from a release period of January 1st, 1996 to October 15th, 2022. Press conferences are a more recent phenomenon and the data aggregated stretched from April 27th, 2011 to October 15th, 2022. We obtained the data by leveraging BeautifulSoup, Selenium, and manual downloading from \\\\url{http://www.federalreserve.gov/}. Regex tools were used to clean the data, which was stored in CSV or Excel format for processing. Sentence tokenization, using the library NLTK \\\\cite{bird2009natural} was done and datasets for each data category were initialized.\\n\\n\\\\paragraph{FOMC Raw Text Data} The overview of our initial raw text dataset is presented in Panel A of Table~\\\\ref{tb:raw_text_data_info}.\\nInitial observations show that meeting minutes and speeches composed the bulk of our data, due to the recency of press conference transcripts. In addition, we also isolated only sentences where the speaker is designated as the Federal Reserve chair and the sentence was not a question in press conference transcripts, so this also served to reduce the data size.\\nAcross all forms of data, we had higher average words per sentence than the typical English language sentence, which averages 15 to 20 words \\\\cite{cutts2020oxford}. \\n\\nOur initial raw text data encompassed decades worth of crucial FOMC statements, however, a plethora of noise persisted in the data.\\nUnrelated sentences riddled the datasets and a filter was needed to isolate key sentences relevant to changes in the federal reserve\\'s monetary policy stance. In addition, the number of sentences in the raw dataset was too vast to manually label, so a sampling procedure was needed.\\n\\n\\n\\\\paragraph{Data \\\\& Title Filtration}\\nAs a result of data noise, a dictionary filter was developed to isolate sentences that would prove to be meaningful and allow us to determine monetary policy stance. The criteria for the filter was based on the dictionary developed by \\\\citet{gorodnichenko2021voice}. Any sentence that contained an instance of the words outlined in panel A1 or B1 in Table \\\\ref{tb:rule-based}\\nwould be kept, while anything else would be filtered out. The sentences kept were considered \"target\" sentences or textual data that we consider pertinent and later used to sample from and annotate. \\n\\n\\\\begin{table}[ht]\\n\\\\centering\\n\\\\footnotesize\\n\\\\begin{tabular}{p{0.22\\\\textwidth}|p{0.2\\\\textwidth}}\\n\\\\hline\\n\\\\textbf{Panel A1} & \\\\textbf{Panel B1}\\\\\\\\\\n\\\\hline\\ninflation expectation, interest rate, bank rate, fund rate, price, economic activity, inflation, employment\\n& \\nunemployment, growth, exchange rate, productivity, deficit, demand, job market, monetary policy\\\\\\\\\\n\\\\hline\\n\\\\textbf{Panel A2} & \\\\textbf{Panel B2}\\\\\\\\\\n\\\\hline\\nanchor, cut, subdue, decline, decrease, reduce, low, drop, fall, fell, decelerate, slow, pause, pausing, stable, non-accelerating, downward, tighten & \\nease, easing, rise, rising, increase, expand, improve, strong, upward, raise, high, rapid \\\\\\\\\\n\\\\hline\\n\\\\textbf{Panel C} \\\\\\\\\\n\\\\hline\\nweren\\'t, were not, wasn\\'t, was not, did not, didn\\'t, do not, don\\'t, will not, won\\'t \\\\\\\\\\n\\\\hline\\n\\n\\\\end{tabular}\\n\\\\caption{Rule-based dictionary used by \\\\citeauthor{gorodnichenko2021voice}}\\n\\\\label{tb:rule-based}\\n\\\\end{table}\\n\\nOur dictionary filter was also applied to speech data. Speech data was the largest dataset derived from web scraping, however, speeches contained the most noise, owing to many non-monetary policy speeches.\\nUnlike the meeting minutes and press conference transcripts, speech data was accompanied with a title, so to isolate only relevant FOMC speeches to sample from, we applied the dictionary filter discussed in Table \\\\ref{tb:rule-based} onto the title of each speech. We justify this procedure in Table \\\\ref{tb:speech-filter} as this methodology results in the greatest \"target\" sentence per file. Overall, the filtration process isolated relevant files and \"target\" sentences in our raw data and set the stage for later sampling. The filter\\'s impact on the raw data is presented in Panel B of Table \\\\ref{tb:raw_text_data_info}.\\n\\n\\n\\n\\\\begin{table*}\\n\\\\centering\\n\\\\footnotesize\\n\\\\begin{tabular}{ccccc}\\n\\\\hline\\n\\\\textbf{Type} & \\\\textbf{\\\\# Files} &\\\\textbf{\\\\# Sentences} & \\\\textbf{\\\\# Target Sentences} & \\\\textbf{\\\\# Target Sentences per File} \\\\\\\\\\n\\\\hline\\nAll Speech Titles & 1,026 & 108,463 & 27,221 & 26.53\\\\\\\\\\nNon-Filtered Speech Titles & 825 & 84,833 & 14,756 & 17.89 \\\\\\\\\\nFiltered Speech Titles & 201 & 23,630 & 12,465 & \\\\textbf{62.01}\\\\\\\\\\n\\\\hline \\n\\\\end{tabular}\\n\\\\caption{Details on the speech title filter methodology}\\n\\\\label{tb:speech-filter}\\n\\\\end{table*}\\n\\n%%%%%%%%%%%%%%%%%%%%%%\\n\\\\begin{table*}\\n\\\\centering\\n\\\\footnotesize\\n\\\\begin{tabular}{cccccc}\\n\\\\hline\\n\\\\textbf{Event} & \\\\textbf{Years} & \\\\textbf{\\\\# Files} & \\\\textbf{\\\\# Sentences} & \\\\textbf{\\\\# Words}  & \\\\textbf{Avg. Words in Sentence} \\\\\\\\\\n\\\\hline\\n\\\\multicolumn{6}{c}{Panel A: Pre-Filter}\\\\\\\\\\n\\\\hline\\nMeeting Minutes & 1996 - 2022 & 214 & 44,923 & 1,346,674  & 29.98 \\\\\\\\\\nMeeting Press Conferences & 2011-2022 & 63 & 19,068 & 468,941  & 24.59 \\\\\\\\\\nSpeeches & 1996-2022 & 1,026 &  108,463 & 3,222,285  & 29.71 \\\\\\\\\\n\\\\hline\\n\\\\multicolumn{6}{c}{Panel B: Post-Filter}\\\\\\\\\\n\\\\hline\\nMeeting Minutes & 1996 - 2022 & 214 & 20,618 & 692,759  & 33.60 \\\\\\\\\\nMeeting Press Conferences & 2011-2022 & 63 & 5,086 & 160,574  & 31.57 \\\\\\\\\\nSpeeches & 1996-2022 & 201 & 12,465 & 447,974  & 37.62 \\\\\\\\\\n\\\\hline\\n\\\\end{tabular}\\n\\\\caption{Details on the text data covered from FOMC}\\n\\\\label{tb:raw_text_data_info}\\n\\\\end{table*}\\n\\n%%%%%%%%%%%%%%%%%%%%%%\\n\\n\\\\paragraph{Sampling and Manual Annotation} As our data was unlabeled, our analysis necessitated the usage of manual labeling. To efficiently develop a manually labeled dataset, sampling was required. Our sampling procedure was to extract 5 random sentences and compile a larger data set. If fewer than 5 sentences were present in the file, all sentences were added. This sampling procedure resulted in a 1,070-sentence Meeting Minutes dataset, a 315-sentence Press Conference dataset, and a 994-sentence Speech dataset. For the labeling process, sentences were categorized into three classes (0: Dovish, 1: Hawkish, and 2: Neutral). We annotate each category of the data as a model trained on various categories as a model trained on the same category of data does not perform optimally. We provide evidence for this claim in Appendix \\\\ref{ap:transfer_learning}. \\n\\n% \\\\\\\\\\n% $sentence_i = $ $\\\\begin{cases} \\n%       0 & \"Dovish\" \\\\\\\\\\n%       1 & \"Hawkish\" \\\\\\\\\\n%       2 & \"Neutral\"\\n%    \\\\end{cases}$\\n% \\\\\\\\ \\\\\\\\\\n\\nDovish sentences were any sentence that indicates future monetary policy easing. Hawkish sentences were any sentence that would indicate a future monetary policy tightening. Meanwhile, neutral sentences were those with mixed sentiment, indicating no change in the monetary policy, or those that were not directly related to monetary policy stance.\\n\\nThe labeling was conducted by two different annotators and done independently to reduce potential labeling bias. Each annotator\\'s labeling was compared against each other and validated to ensure the consistency of the labeling results. The detail on the annotation agreement is provided in Appendix \\\\ref{sec:agreement_ann}. The labeling was conducted according to a predefined annotation guide, which is provided in Appendix \\\\ref{sec:appendix_manual_ann}. The guide is broken down into key sections such as economic status, dollar value change, energy/house prices, future expectations, etc.\\n\\n\\\\paragraph{Sentence Splitting} A common occurrence in the labeling process was the existence of intentional mixed tone. The Federal Reserve by purpose serves to maintain financial/economic stability and any statement they make is projected in a moderating manner to reduce the chance of excess market reaction. As a result, the Fed is known to project a stance but often accompanies this with a moderating statement that serves as a counterweight to the original stance. This produces a greater occurrence of neutral sentences. To address this possibility, we instituted sentence splitting to separate the differing stances. Initially, we implemented the lexicon-based package SentiBigNomics \\\\citep{SentiBigNomics} for sentence splitting, but it resulted in poor performance, causing us to pivot our approach. We developed a custom sentence-splitting method based on keywords. In Fed statements, the counter-statements are produced after a connective contrasting word. We carried sentence splits at the presence of the following keywords in a given statement: \"but\", \"however\", \"even though\", \"although\", \"while\", \";\". A sentence split was valid if each split segment contained a key word present in Table \\\\ref{tb:rule-based}. Statistics on the dataset before and after splitting are provided in Table \\\\ref{tb:before_after_split}. \\n\\n\\\\begin{table}[h]\\n\\\\centering\\n\\\\footnotesize\\n\\\\begin{tabular}{ccc}\\n\\\\hline\\n\\\\textbf{Event} & \\\\textbf{Before split} & \\\\textbf{After split} \\\\\\\\\\n\\\\hline\\nMeeting Minutes & 1,070 & 1,132 \\\\\\\\\\nMeeting Press Conferences & 315 & 322 \\\\\\\\\\nSpeeches & 994 & 1,026  \\\\\\\\\\n\\\\hline\\nTotal & 2,379 & 2,480\\\\\\\\\\n\\\\hline\\n\\\\end{tabular}\\n\\\\caption{Number of sentences in the labeled dataset before and after splitting for each event. }\\n\\\\label{tb:before_after_split}\\n\\\\end{table}\\n\\n\\n\\\\subsection{Economic Data}\\n\\\\paragraph{CPI and PPI} We collect Consumer Price Index (CPI) data, and Producer Price Index (PPI) data from FRED\\\\footnote{\\\\url{https://fred.stlouisfed.org}}. The data is available at the monthly frequency for the first day of each month. Throughout the paper, we use percentage change from last year as CPI and PPI inflation measures. \\n\\n\\\\paragraph{US Treasury} We collect US treasury yield data for different maturities from the U.S. Department of the Treasury\\\\footnote{\\\\url{https://home.treasury.gov}}. It provides a daily yield of bonds for various maturities.  \\n\\n\\\\paragraph{QQQ Index} We collect the adjusted closing index price of QQQ from Yahoo Finance\\\\footnote{\\\\url{https://finance.yahoo.com/quote/QQQ/history?p=QQQ}}. It contains daily QQQ index data since March 9, 1999. \\n\\n\\nsection'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_chunks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "806a3a8f-3c91-477a-95e4-c9df289ac3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\\\section*{Limitations}\\nIn this article, we focus only on meeting minutes, speech, and press conference data. Many other text datasets such as transcripts from congressional and senate testimonies, beige books, green books, etc can be incorporated to understand pre-FOMC drift better. We don't use audio or video features in constructing the measure, which might contain additional information. It can be an interesting future study to compare measures generated from FOMC text with an alternate measure that can be constructed from the news or social media data. In dataset construction, while splitting sentences, we use a simple rule-based approach. We leave it as an open problem for future researchers to find better methods for splitting sentences with opposite tones. \\n\\nIn our trading strategy construction, we do not include transaction fees as it involves low-frequency trading. In the future, one can use our model and data to construct a high-frequency trading strategy as well. In addition, a more comprehensive zero-shot and few-shot generative LLM benchmark with open-source models can be performed to provide a better comparison. \\n\\nsection\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_chunks[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1047c6-4de5-49f1-a022-3c14b65565e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2e4d3ab-796f-414f-b47b-c87f0c562e98",
   "metadata": {},
   "source": [
    "## LLM Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d09f23cd-b211-4caf-adaa-ac1d459c9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(prompt):\n",
    "    \"\"\"\n",
    "    Rutwik ask llm\n",
    "    \"\"\"\n",
    "    prompt_json = [{'role': 'user', 'content': prompt}]\n",
    "\n",
    "    model_source = 'meta-llama'\n",
    "    model_name = 'Llama-3-70b-chat-hf'\n",
    "    model_str = f'{model_source}/{model_name}'\n",
    "\n",
    "    chat_completion = client_together.chat.completions.create(\n",
    "        model=model_str,\n",
    "        messages=prompt_json,\n",
    "        temperature=0,\n",
    "        max_tokens=512\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def prompt_discuss_limitations(parsedText):\n",
    "    \"\"\"\n",
    "    Prompt discuss limitations\n",
    "    \"\"\"\n",
    "    prompt = f'''\n",
    "    You are an assistant to a researcher who intends to submit their research paper to the ACL Conference. To avoid desk rejection, the researcher wants to ensure their paper meets the benchmarks set by the Responsible NLP Research Checklist.\n",
    "\n",
    "    Your task is to analyze the provided research paper and answer the following question from the checklist: \"Did you discuss the limitations of your work?\"\n",
    "\n",
    "    If the answer is YES, provide the section number. If the answer is NO, provide a justification.\n",
    "\n",
    "    Research Paper: ```{parsedText}```\n",
    "\n",
    "    Your response should be in JSON format with the keys \"answer\" (YES/NO) and \"justification\" (if YES, the section number; if NO, the justification).\n",
    "    '''\n",
    "    return ask_llm(prompt)\n",
    "\n",
    "def prompt_discuss_potential_risks(parsedText):\n",
    "    \"\"\"\n",
    "    Prompt discuss potential risks\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f'''\n",
    "    You are an assistant to a researcher who intends to submit their research paper to the ACL Conference. To avoid desk rejection, the researcher wants to ensure their paper meets the benchmarks set by the Responsible NLP Research Checklist.\n",
    "\n",
    "    Your task is to analyze the provided research paper and answer the following question from the checklist: \"Did you discuss any potential risks of your work?\"\n",
    "\n",
    "    If the answer is YES, provide the section number. If the answer is NO, provide a justification.\n",
    "\n",
    "    Research Paper: ```{parsedText}```\n",
    "\n",
    "    Your response should be in JSON format with the keys \"answer\" (YES/NO) and \"justification\" (if YES, the section number; if NO, the justification).\n",
    "    '''\n",
    "    return ask_llm(prompt)\n",
    "\n",
    "def prompt_summarize_claims(parsedText):\n",
    "    \"\"\"\n",
    "    Prompt summarize claims\n",
    "    \"\"\"\n",
    "    prompt = f'''\n",
    "    You are an assistant to a researcher who intends to submit their research paper to the ACL Conference. To avoid desk rejection, the researcher wants to ensure their paper meets the benchmarks set by the Responsible NLP Research Checklist.\n",
    "\n",
    "    Your task is to analyze the provided research paper and answer the following question from the checklist: \"Do the abstract and introduction summarize the paper’s main claims?\"\n",
    "\n",
    "    If the answer is YES, provide the section number. If the answer is NO, provide a justification.\n",
    "\n",
    "    Research Paper: ```{parsedText}```\n",
    "\n",
    "    Your response should be in JSON format with the keys \"answer\" (YES/NO) and \"justification\" (if YES, the section number; if NO, the justification).\n",
    "    '''\n",
    "    return ask_llm(prompt)\n",
    "\n",
    "def prompt_cite_creators(parsedText):\n",
    "    \"\"\"\n",
    "    Prompt cite creators\n",
    "    \"\"\"\n",
    "    prompt = f'''\n",
    "    You are an assistant to a researcher who intends to submit their research paper to the ACL Conference. To avoid desk rejection, the researcher wants to ensure their paper meets the benchmarks set by the Responsible NLP Research Checklist.\n",
    "\n",
    "    Your task is to analyze the provided research paper and answer the following question from the checklist: \"Did you cite the creators of artifacts you used?\"\n",
    "\n",
    "    If the answer is YES, provide the section number. If the answer is NO, provide a justification.\n",
    "\n",
    "    Research Paper: ```{parsedText}```\n",
    "\n",
    "    Your response should be in JSON format with the keys \"answer\" (YES/NO) and \"justification\" (if YES, the section number; if NO, the justification).\n",
    "    '''\n",
    "    return ask_llm(prompt)\n",
    "\n",
    "def prompt_discuss_license(parsedText):\n",
    "    \"\"\"\n",
    "    Prompt discuss license\n",
    "    \"\"\"\n",
    "    prompt = f'''\n",
    "    You are an assistant to a researcher who intends to submit their research paper to the ACL Conference. To avoid desk rejection, the researcher wants to ensure their paper meets the benchmarks set by the Responsible NLP Research Checklist.\n",
    "\n",
    "    Your task is to analyze the provided research paper and answer the following question from the checklist: \"Did you discuss the license or terms for use and/or distribution of any artifacts?\"\n",
    "\n",
    "    If the answer is YES, provide the section number. If the answer is NO, provide a justification.\n",
    "\n",
    "    Research Paper: ```{parsedText}```\n",
    "\n",
    "    Your response should be in JSON format with the keys \"answer\" (YES/NO) and \"justification\" (if YES, the section number; if NO, the justification).\n",
    "    '''\n",
    "    return ask_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca043f0-eda5-4de3-a838-f8becf9d0118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
